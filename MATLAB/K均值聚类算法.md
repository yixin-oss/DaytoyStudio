---
title: K均值聚类算法
tags:
- MATLAB
- 聚类
- 机器学习
categories: 机器学习
---

# 序

​        K均值聚类算法(K-means algorithm)是经典的数据划分方法, 其基本思想是: 将给定的包含$n$个数据的数据集划分成$k(k<n)$组, 每一个分组代表一类(簇), 并且这些类满足以下条件

- 不能出现空类;
- 每一个数据属于且仅属于某一类.

算法从初始分组方法开始, 通过迭代的方法不断优化数据集分类的结果.

​        算法的大致流程为: 首先随机从数据集中选出$k$个点, 每个点代表初始簇的聚类中心, 然后计算剩余点到聚类中心的距离, 将它们分配到最近的簇, 接着重新计算每一簇的平均值作为新的聚类中心, 根据数据点当前的聚类情况进行调整, 整个过程不断重复, 如果两次相邻调整没有明显变化, 则说明算法基本到达收敛, 已经形成了合理的簇, 可以终止运行, 具体的终止准则可以是以下任何一个条件

- 没有数据点被重新分配给不同的簇;
- 聚类中心不再发生变化;
- 误差平方和局部最小.

下面我们给出K均值聚类算法的主要步骤.

## 算法步骤

------

**输入**: 包含$n$个数据的数据集, 聚类个数$k$.

**输出**: 满足方差最小标准的$k$个聚类.

**步骤1** 从$n$个数据中任意选取$k$个作为初始聚类中心;

**步骤2** 计算其余数据到各个初始聚类中心的距离, 根据最小距离对它们进行划分;

**步骤3** 重新计算每类的聚类中心, 直到聚类中心不再变化. 此时有
$$
min E=\sum_{j=1}^{k}\sum_{x_j\in w_j}||x_j-m_j||^2,
$$
其中, $x_i$为第$i$个样本点的位置; $m_j$为第$j$个聚类中心的位置;

**步骤4** 循环第2,3步, 直到每个聚类不再发生变化为止.

------

​        事实上, K均值聚类算法是很典型的基于距离的聚类算法, 采用距离作为相似性的评价指标, 即距离越近则越相似, 算法的最终目标是根据距离得到紧凑且独立的各个簇. 诚然, 该算法的局限性也是十分明显的:

- 聚类数$k$需要事先指定, 然而这个$k$值是非常难以估计的;
- 需要根据初始聚类中心来确定初始划分, 然后再进行优化, 这与许多经典的数值算法事先给定初值再进行迭代求解的过程是相似的, 因此初始值的选择也可能会影响最终的聚类结果;
- 由于算法需要不断对数据点的聚类进行调整, 不断计算新的聚类中心, 对于大样本数据, 算法的计算时间是很长的.
- 算法对于一些离散数据点和$k$值较为敏感, 同样的数据可能会得到不同的聚类结果.

## 数值实例

​        已知有20个样本, 每个样本有2个数据特征, 如下表所示, 对这些数据进行分类.

| $X_1$ |  0   |  1   |  0   |  1   |  2   |  1   |  2   |  3   |  6   |  7   |
| :---: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |
| $X_2$ |  0   |  0   |  1   |  1   |  1   |  2   |  2   |  2   |  6   |  6   |
| $X_1$ |  8   |  6   |  7   |  8   |  9   |  7   |  8   |  9   |  8   |  9   |
| $X_2$ |  6   |  7   |  7   |  7   |  7   |  8   |  8   |  8   |  9   |  9   |

## Code

```matlab
% K-means方法
x=xlsread('data.xlsx'); % 导入数据
[m,n]=size(x);
z1=zeros(2,2);
z=x(1:2,1:2);
% 寻找聚类中心
while 1
    count=zeros(n,1);
    allsum=zeros(2,2);
    for i=1:m
        temp1=sqrt((z(1,1)-x(i,1)).^2+(z(1,2)-x(i,2)).^2);
        temp2=sqrt((z(2,1)-x(i,1)).^2+(z(2,2)-x(i,2)).^2);
        if temp1<temp2
            count(1)=count(1)+1;
            allsum(1,:)=allsum(1,:)+x(i,:);
        else
            count(2)=count(2)+1;
            allsum(2,:)=allsum(2,:)+x(i,:);
        end
    end
        z1(1,:)=allsum(1,:)./count(1);
        z1(2,:)=allsum(2,:)./count(2);
        if z==z1
            break
        else
            z=z1;
        end
end

% 结果显示
disp(z1); % 输出聚类中心
plot(x(:,1),x(:,2),'k*','MarkerSize',10);
hold on
plot(z1(:,1),z1(:,2),'ro','MarkerSize',10);
set(gca,'linewidth',2);
xlabel('特征x1','fontsize',12);
ylabel('特征x2','fontsize',12);
title('K-means分类图','fontsize',12);
```

![kmeans](https://gitee.com/yixin-oss/blogImage/raw/master/img/kmeans.png)

























